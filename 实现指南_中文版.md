# LEOD 实现指南（中文版）
## 关键模块与调试

---

## 第1部分：循环骨干网络实现

### 1.1 LSTM状态初始化与管理

**文件位置**：`modules/utils/detection.py`

```python
class RNNStates:
    """
    在流式数据加载中维护每个工作进程的LSTM状态。
    
    为什么需要？
    -----------
    在分布式训练中，不同工作进程独立加载数据。
    如果混淆状态，会导致：
    1. 工作进程A的状态被工作进程B污染
    2. 序列之间的状态泄漏
    3. 梯度计算错误
    
    解决方案：按worker_id隔离状态
    """
    
    def __init__(self):
        # worker_id → LSTM状态
        # LstmStates = List[(h, c), ...], 每个阶段一对
        self.worker_id_2_states: Dict[int, LstmStates] = {}
    
    def reset(self, worker_id: int, is_first_sample):
        """
        在序列边界重置状态。
        
        参数：
            worker_id: 数据加载工作进程ID
            is_first_sample: 形状[B]的布尔张量
                            True表示该样本是序列的开始
        
        例子：
            # 流式数据：某些样本继续前序列
            is_first = torch.tensor([True, False, False])
            rnn_states.reset(worker_id=0, is_first)
            # → 样本0重置，样本1-2保留前面的状态
            
            # 随机数据：所有样本都是新序列的开始
            is_first = torch.tensor([True, True, True])
            rnn_states.reset(worker_id=0, is_first)
            # → 全部重置（预期，无时间关联）
        """
        if worker_id not in self.worker_id_2_states:
            self.worker_id_2_states[worker_id] = None
            return
        
        if isinstance(is_first_sample, torch.Tensor):
            if is_first_sample.all():
                # 重置全部状态
                self.worker_id_2_states[worker_id] = None
            else:
                # 选择性重置（高级用法，很少用）
                current_states = self.worker_id_2_states[worker_id]
                for idx in is_first_sample.nonzero():
                    # 重置各阶段的h和c
                    for stage_idx in range(len(current_states)):
                        h, c = current_states[stage_idx]
                        h[idx] = 0
                        c[idx] = 0
    
    def get_states(self, worker_id: int) -> Optional[LstmStates]:
        """获取该工作进程的前一帧状态（或None）"""
        return self.worker_id_2_states.get(worker_id, None)
    
    def save_states_and_detach(self, worker_id: int, states: LstmStates):
        """
        保存当前状态供下一帧使用，并从计算图分离。
        
        为什么要detach？
        ----------------
        不detach会发生什么：
        
        时间步0: h_0 = LSTM(x_0)
        时间步1: h_1 = LSTM(x_1, h_0)
        时间步2: h_2 = LSTM(x_2, h_1)
        ...
        时间步99: h_99 = LSTM(x_99, h_98)
        
        反向传播：
        loss ← h_99 ← h_98 ← ... ← h_1 ← h_0
        
        问题：
        1. 梯度流经100个时间步（BPTT无截断）
        2. 梯度可能爆炸或消失
        3. 内存占用巨大（保存所有中间h值）
        4. 训练不稳定
        
        解决方案：在批次边界detach
        
        detach后：
        loss ← h_99 [梯度流停止]
        前面的帧：梯度流被切断
        
        优点：
        - LSTM仍然学习：通过权重和当前帧
        - 梯度流在合理范围内
        - 内存使用大幅降低
        - 训练稳定
        """
        detached_states = []
        for state in states:
            if state is None:
                detached_states.append(None)
            else:
                h, c = state
                # detach：h_new是从h_old计算的，但梯度停留于此
                detached_states.append((h.detach(), c.detach()))
        
        self.worker_id_2_states[worker_id] = detached_states
```

### 1.2 训练步骤中的状态流

**文件位置**：`modules/detection.py`，`training_step()`方法

```python
def training_step(self, batch: Any, batch_idx: int):
    """处理L帧的事件序列"""
    
    batch = merge_mixed_batches(batch)  # 统一批次格式
    data = self.get_data_from_batch(batch)
    worker_id = self.get_worker_id_from_batch(batch)
    
    mode = Mode.TRAIN
    
    # ========== 关键步骤1：重置RNN状态 ==========
    ev_tensor_sequence = data[DataType.EV_REPR]      # L帧
    sparse_obj_labels = data[DataType.OBJLABELS_SEQ]  # L个标签对象
    is_first_sample = data[DataType.IS_FIRST_SAMPLE]  # [B] bool
    
    # 在序列边界重置
    self.mode_2_rnn_states[mode].reset(
        worker_id=worker_id,
        indices_or_bool_tensor=is_first_sample
    )
    
    # ========== 关键步骤2：获取前一帧的状态 ==========
    prev_states = self.mode_2_rnn_states[mode].get_states(worker_id=worker_id)
    # prev_states = None （新序列）或 List[(h,c)] （继续前序列）
    
    L = len(ev_tensor_sequence)
    
    # ========== 关键步骤3：循环处理L帧 ==========
    for tidx in range(L):
        # 第t时刻的事件表示
        ev_tensors = ev_tensor_sequence[tidx]  # [B, C, H, W]
        
        # 关键：前向通过，传入前一帧的状态
        backbone_features, states = self.mdl.forward_backbone(
            x=ev_tensors,
            previous_states=prev_states,  # ← 时间依赖！
            token_mask=None
        )
        # backbone_features: Dict[stage_id → [B, C, h, w]]
        # states: List of (h, c) tuples, one per stage
        
        prev_states = states  # 保存给下一帧（还没detach）
        
        # 仅在有标注的帧上计算损失
        current_labels, valid_batch_indices = \
            sparse_obj_labels[tidx].get_valid_labels_and_batch_indices()
        
        if len(current_labels) > 0:
            # 选择对应标注帧的特征
            backbone_feature_selector.add_backbone_features(
                backbone_features=backbone_features,
                selected_indices=valid_batch_indices
            )
            obj_labels.extend(current_labels)
    
    # ========== 关键步骤4：保存状态给下一批 ==========
    self.mode_2_rnn_states[mode].save_states_and_detach(
        worker_id=worker_id,
        states=prev_states  # 现在才detach
    )
    
    # ========== 计算损失 ==========
    selected_backbone_features = \
        backbone_feature_selector.get_batched_backbone_features()
    
    predictions, losses = self.mdl.forward_detect(
        backbone_features=selected_backbone_features,
        targets=labels_yolox
    )
    
    return {'loss': losses['loss']}
```

### 1.3 状态流可视化

```
事件序列处理示例（L=10帧，B=2样本）

时间线：
t=0:
  ├─ is_first=[True, False]
  ├─ reset() → 样本0重置状态h=0,c=0; 样本1保留
  ├─ forward(x_0, h=0,c=0) 样本0
  ├─ forward(x_0, h_prev, c_prev) 样本1
  └─ 输出: h_0, c_0

t=1:
  ├─ get_states() → 获取t=0的状态
  ├─ forward(x_1, h_0, c_0) 样本0
  ├─ forward(x_1, h_prev, c_prev) 样本1
  └─ 输出: h_1, c_1
  └─ 保存状态（detach）

t=2-9:
  └─ 重复...

下一批（同一序列的样本1）:
  ├─ is_first=[False, True]  # 样本0继续，样本1重启
  ├─ reset()
  ├─ get_states() → 获取t=9的状态
  ├─ forward(x_10, h_9, c_9) 样本0 继续
  ├─ forward(x_10, h=0, c=0) 样本1 新序列
  └─ 梯度流 → 样本0有时间依赖，样本1无
```

---

## 第2部分：伪标签生成管道

### 2.1 TTA聚合算法

**文件位置**：`modules/pseudo_labeler.py`，第37-91行

```python
def tta_postprocess(preds: List[ObjectLabels],
                    conf_thre: float = 0.7,
                    nms_thre: float = 0.45) -> List[ObjectLabels]:
    """
    合并多个TTA增强的预测。
    
    TTA四个版本：
    1. 原始 (orig)
    2. 水平翻转 (hflip) - 翻转后箱子坐标已还原
    3. 时间翻转 (tflip) - 反转帧序后坐标已调整
    4. 双重翻转 (hflip+tflip)
    
    目的：提升伪标签质量
    - 多个模型"投票"
    - 置信度一致 → 真正例
    - 置信度不一致 → 假正例 (过滤)
    """
    
    if len(preds) == 0:
        return preds
    
    pad = preds[0].new_zeros()
    output = [pad] * len(preds)
    
    for i, pred in enumerate(preds):
        # 跳过GT标签（不过滤）
        if pred.is_gt_label().any():
            output[i] = pred
            continue
        
        # 转换格式：(x,y,w,h) → (x1,y1,x2,y2) 即xyxy
        t = pred.t.unsqueeze(1)  # [N, 1]
        pred_tensor = pred.get_labels_as_tensors(format_='prophesee')
        # pred_tensor: [N, 7]
        # 包含: [x1, y1, x2, y2, obj_conf, cls_conf, cls_idx]
        
        if not pred_tensor.size(0):
            continue  # 空帧
        
        # ========== 步骤1：置信度过滤 ==========
        obj_conf = pred_tensor[:, 4]      # 目标性置信度 [N]
        class_conf = pred_tensor[:, 5]    # 类别置信度 [N]
        
        # 关键：使用联合置信度
        combined_conf = obj_conf * class_conf  # [N]
        # 这比单独用obj_conf或cls_conf更可靠
        # 因为需要两个都高才能是真正例
        
        conf_mask = (combined_conf >= conf_thre)  # [N] bool
        detections = pred_tensor[conf_mask]      # 保留高置信度
        t = t[conf_mask]
        
        if not detections.size(0):
            continue  # 全被过滤
        
        # ========== 步骤2：NMS (非极大值抑制) ==========
        # 目的：移除重叠的检测（同一目标的多个框）
        
        nms_out_index = ops.batched_nms(
            detections[:, :4],              # 框坐标
            detections[:, 4] * detections[:, 5],  # 联合置信度
            detections[:, 6].long(),        # 类别ID
            nms_thre                        # IoU阈值
        )
        
        detections = detections[nms_out_index]
        t = t[nms_out_index]
        
        # ========== 步骤3：转换回ObjectLabels格式 ==========
        # 从(x1,y1,x2,y2)转换回(x,y,w,h)
        xywh = xyxy2xywh(detections[:, :4],
                          format_='corner', last4=True)
        obj_conf_out, class_conf_out, cls_id = \
            torch.split(detections[:, 4:], 1, dim=1)
        
        # 重新组合: [t, x, y, w, h, cls_id, cls_conf, obj_conf]
        detections = th.cat([t, xywh, cls_id, class_conf_out, obj_conf_out], dim=1)
        output[i] = ObjectLabels(detections, pad.input_size_hw)
    
    return output
```

### 2.2 跟踪过滤实例

**文件位置**：`modules/pseudo_labeler.py`，第201-260行

```python
@staticmethod
def _track(labels: List[ObjectLabels],
           frame_idx: List[int],
           min_track_len: int = 6,
           inpaint: bool = False):
    """
    使用SORT风格的跟踪器过滤伪标签。
    
    核心思想：
    --------
    真正的目标：在多个帧中被追踪到（轨迹长）
    假正例：随机出现1-2帧（轨迹短）
    
    使用线性速度模型：
    新位置 = 旧位置 + 速度 * Δt
    """
    
    model = LinearTracker(img_hw=labels[0].input_size_hw)
    
    # ========== 步骤1：供给所有帧数据给跟踪器 ==========
    # 无论该帧是否有检测，都调用update
    # 跟踪器在无检测帧预测位置
    
    for f_idx in range(max(frame_idx) + 1):
        if f_idx not in frame_idx:
            # 该帧无检测
            model.update(f_idx)  # 跟踪器做预测
            continue
        
        # 该帧有检测
        idx = frame_idx.index(f_idx)
        obj_label: ObjectLabels = labels[idx]
        
        # 获取[x,y,w,h,cls_id]格式
        obj_label.numpy_()
        bboxes = obj_label.get_xywh(format_='center', add_class_id=True)
        is_gt = obj_label.is_gt_label()
        
        # 喂给跟踪器
        model.update(frame_idx=f_idx, dets=bboxes, is_gt=is_gt)
    
    model.finish()  # 完成追踪
    
    # ========== 步骤2：过滤短轨迹 ==========
    
    remove_idx = []  # 要删除的框索引
    bbox_idx = 0
    
    for obj_label in labels:
        for _ in range(len(obj_label)):
            tracker = model.get_bbox_tracker(bbox_idx)
            
            # 决策：保留还是删除？
            keep = False
            
            if not tracker.done:
                # 轨迹仍在进行（后面还有检测）
                # → 可能是真正例（还没完全消失）
                keep = True
            elif tracker.is_gt:
                # 原始GT标签
                # → 必须保留
                keep = True
            elif tracker.hits >= min_track_len:
                # 轨迹很长（>=6个命中）
                # → 可能是真正例（连续被看到）
                keep = True
            else:
                # 轨迹很短（<6个命中）
                # → 可能是假正例（随机1-2帧）
                keep = False
            
            if not keep:
                remove_idx.append(bbox_idx)
            
            bbox_idx += 1
    
    # ========== 步骤3：填充遗漏检测 (可选) ==========
    # 在有效轨迹遗漏的帧上添加预测框
    
    inpainted_bbox = {}
    
    if inpaint:
        for tracker in model.prev_trackers:
            # 该轨迹是否"好"？
            is_good = (tracker.done and tracker.hits >= min_track_len) or \
                      tracker.is_gt
            
            if not is_good:
                continue  # 跳过坏轨迹
            
            # 该轨迹预测了哪些帧（没有检测的帧）？
            for f_idx, bbox in tracker.missed_bbox.items():
                # bbox: [x,y,w,h,cls_id] 由跟踪器预测
                if f_idx not in inpainted_bbox:
                    inpainted_bbox[f_idx] = []
                
                inpainted_bbox[f_idx].append(bbox)
    
    return remove_idx, inpainted_bbox
```

### 2.3 跟踪过程示例详解

```
帧索引:      0    1    2    3    4    5    6
检测框:     obj1 obj1  —    —   obj1  —   obj1
           obj2 obj2 obj2 obj2 obj2  —    —

┌─── 目标1 的轨迹 ───┐
│ t=0: 检测到 hit✓ hits=1
│ t=1: 检测到 hit✓ hits=2
│ t=2: 遗漏   —   预测: bbox @ (x',y')
│ t=3: 遗漏   —   预测: bbox @ (x'',y'')
│ t=4: 检测到 hit✓ hits=3
│ t=5: 遗漏   —   预测: bbox @ (x''',y''')
│ t=6: 检测到 hit✓ hits=4
│
│ 最终: hits=4 < min_track_len=6 ✗
│ 决定: 删除 (假正例，轨迹太短)
└────────────────────┘

┌─── 目标2 的轨迹 ───┐
│ t=0: 检测到 hit✓ hits=1
│ t=1: 检测到 hit✓ hits=2
│ t=2: 检测到 hit✓ hits=3
│ t=3: 检测到 hit✓ hits=4
│ t=4: 检测到 hit✓ hits=5
│ t=5: 遗漏   —   预测: bbox @ (x5,y5)
│ t=6: 遗漏   —   预测: bbox @ (x6,y6)
│
│ 最终: hits=5 < 6，但tracker.done=True
│ 并且有预测框在t=5,6
│ 
│ 如果inpaint=True:
│   在帧5,6添加预测框 → 密集化标注
│ 
│ 决定: 保留并填充 (真正例)
└────────────────────┘

结果：高质量伪标签 ✓
```

---

## 第3部分：调试与问题排查

### 3.1 梯度爆炸问题

**症状**：
```
RuntimeError: CUDA out of memory
或
torch.isnan(loss) == True
或
loss → inf
```

**根本原因**：LSTM状态没有正确detach，梯度流穿越100+个时间步

**诊断**：
```python
# 检查状态是否detach
for h, c in prev_states:
    if h.requires_grad:  # 如果为True，说明没有detach！
        print("ERROR: LSTM state has requires_grad=True!")
        print("梯度会穿越批次边界，导致爆炸")
```

**修复**：
```python
# 确保save_states_and_detach()正确执行
self.mode_2_rnn_states[mode].save_states_and_detach(...)
# 检查：
assert not prev_states[0][0].requires_grad  # h
assert not prev_states[0][1].requires_grad  # c
```

### 3.2 伪标签噪声问题

**症状**：
```
Round 0: 28% mAP
Round 1: 25% mAP (下降!)
```

**原因**：伪标签质量太差，模型学到了错误

**诊断**：
```bash
# 评估伪标签精度
python val_dst.py \
  model=pseudo_labeler \
  dataset=gen1x0.01_ss \
  dataset.path=./datasets/pseudo_gen1/gen1x0.01_ss-1round

# 查看输出：
# Precision: 0.70 (太低！)
# Recall: 0.80
```

**修复**：
```yaml
# 提高置信度阈值
model:
  pseudo_label:
    obj_thresh: 0.05  # 从0.01提高
    cls_thresh: 0.05

# 增加跟踪最小长度
model:
  pseudo_label:
    filter:
      min_track_len: 8  # 从6提高到8
```

**重新生成伪标签**：
```bash
python predict.py \
  model=pseudo_labeler \
  checkpoint="./ckpts/gen1x0.01_ss/last.ckpt" \
  model.pseudo_label.obj_thresh=0.05 \
  model.pseudo_label.cls_thresh=0.05 \
  model.pseudo_label.filter.min_track_len=8 \
  save_dir=./datasets/pseudo_gen1/gen1x0.01_ss-1round-v2
```

### 3.3 内存溢出问题

**症状**：
```
CUDA out of memory at allocation of X GB
```

**原因**：流式数据太长或模型太大

**快速修复**（不需要重新训练）：
```yaml
# 减少流式数据权重
dataset:
  train:
    mixed:
      w_stream: 0.5    # 从1.0降低
      w_random: 1.0    # 保持不变

# 结果: 33% 流式 + 67% 随机 (更快)

# 或减少序列长度
dataset:
  sequence_length: 5   # 从10降低 (但时间建模差)
```

---

## 第4部分：性能优化技巧

### 4.1 加速伪标签生成

**当前速度**：7-10小时/Gen1，10-12小时/Gen4

**优化方案**：
```bash
# 1. 使用更多工作进程
python predict.py \
  ... \
  hardware.num_workers.eval=16  # 从8提高

# 2. 增加批大小
batch_size.eval=16  # 从8提高

# 3. 降低精度（FP16混合精度）
training.precision=16
```

**预期**：30-40%加速

### 4.2 混合采样比例调整

```yaml
# 如果训练太慢（流式数据瓶颈）
dataset.train.mixed:
  w_stream: 0.5   # 33% 流式
  w_random: 1.0   # 67% 随机
# 结果：快30-40%，但泛化能力下降~1% mAP

# 如果过拟合明显（验证mAP下降）
dataset.train.mixed:
  w_stream: 2     # 67% 流式
  w_random: 1     # 33% 随机
# 结果：慢30-40%，但泛化更好
```

---

## 总结表格

| 问题 | 症状 | 快速诊断 | 修复方案 |
|------|------|--------|--------|
| **梯度爆炸** | NaN loss | h.requires_grad==True | detach() |
| **伪标签差** | Round1 mAP下降 | Precision < 0.8 | 提高阈值 |
| **内存溢出** | CUDA OOM | 流式数据过长 | 减少w_stream |
| **训练慢** | iter/sec < 0.5 | num_workers占用 | 增加batch size |

