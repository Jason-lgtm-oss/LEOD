# LEOD å¿«é€Ÿå¤ç°æŒ‡å—ï¼ˆä¸­æ–‡ç‰ˆï¼‰
## ä»é›¶åˆ°SOTAç»“æœ

---

## æ¦‚è§ˆï¼šå®Œæ•´æµç¨‹è€—æ—¶

| é˜¶æ®µ | è€—æ—¶ | å…³é”®æ­¥éª¤ | è¾“å‡º |
|------|------|--------|------|
| **æ­¥éª¤1ï¼šç¯å¢ƒ** | 15åˆ†é’Ÿ | è£…åŒ…+ä¸‹æ•°æ® | å¯è®­ç»ƒç¯å¢ƒ |
| **æ­¥éª¤2ï¼šåŸºçº¿** | 2å°æ—¶ | è®­ç»ƒ1%æ ‡æ³¨ | ~28-30% mAP |
| **æ­¥éª¤3ï¼šä¼ªæ ‡ç­¾** | 7-10å°æ—¶ | æ¨¡å‹æ¨ç† | 100-150 MBä¼ªæ ‡ç­¾ |
| **æ­¥éª¤4ï¼šè‡ªè®­ç»ƒ** | 2å°æ—¶ | åœ¨ä¼ªæ ‡ç­¾ä¸Šè®­ç»ƒ | ~37.6% mAP |
| **æ­¥éª¤5ï¼šè¯„ä¼°** | 1å°æ—¶ | æµ‹è¯•é›†éªŒè¯ | æœ€ç»ˆæŒ‡æ ‡ |
| **æ€»è®¡** | **12-14å°æ—¶** | **5ä¸ªæ­¥éª¤** | **SOTAæ€§èƒ½** |

---

## æ­¥éª¤1ï¼šç¯å¢ƒæ­å»ºï¼ˆ15åˆ†é’Ÿï¼‰

### 1.1 åˆ›å»ºCondaç¯å¢ƒ

```bash
# åˆ›å»º
conda create -n leod python=3.9
conda activate leod

# éªŒè¯
python --version  # åº”è¯¥æ˜¾ç¤º3.9.x
```

### 1.2 å®‰è£…æ ¸å¿ƒä¾èµ–

```bash
# PyTorch 2.0 + CUDA
conda install -y pytorch==2.0.0 torchvision==0.15.0 \
  pytorch-cuda=11.8 -c pytorch -c nvidia

# éªŒè¯PyTorch
python -c "import torch; print(torch.cuda.is_available())"
# åº”æ˜¾ç¤ºï¼šTrue
```

### 1.3 å®‰è£…PythonåŒ…

```bash
pip install -q \
  pytorch-lightning==1.8.6 \
  hydra-core==1.3.2 \
  wandb==0.14.0 \
  torchdata==0.6.0 \
  h5py==3.8.0 \
  hdf5plugin \
  opencv-python \
  numpy \
  tqdm

# éªŒè¯
python -c "import pytorch_lightning; import hydra; print('âœ“ å®‰è£…æˆåŠŸ')"
```

### 1.4 å®‰è£…nervå·¥å…·åŒ…

```bash
# å…‹éš†å’Œå®‰è£…
git clone https://github.com/Wuziyi616/nerv.git
cd nerv
git checkout v0.4.0
pip install -e .
cd ..

# éªŒè¯
python -c "from nerv.utils import sort_file_by_time; print('âœ“ nervå®‰è£…æˆåŠŸ')"
```

### 1.5 ä¸‹è½½æ•°æ®é›†

```bash
# åˆ›å»ºç›®å½•
mkdir -p datasets

# Gen1æ•°æ®é›†
wget https://download.ifi.uzh.ch/rpg/RVT/datasets/preprocessed/gen1.tar
tar -xf gen1.tar -C datasets/

# Gen4æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
wget https://download.ifi.uzh.ch/rpg/RVT/datasets/preprocessed/gen4.tar
tar -xf gen4.tar -C datasets/

# éªŒè¯
ls -lh datasets/gen1/  # åº”è¯¥æœ‰event_data.h5ç­‰æ–‡ä»¶
```

### 1.6 (å¯é€‰) ä¸‹è½½é¢„è®­ç»ƒæƒé‡

```bash
# ä»Google Driveä¸‹è½½ï¼ˆç”¨æµè§ˆå™¨ï¼‰
# https://drive.google.com/file/d/1xBzFovvNbrtBt0YwYcvvrjbV8ozAdCUK

# è§£å‹
mkdir -p pretrained
unzip pretrained_weights.zip -d pretrained/

# æˆ–ç›´æ¥ç”¨è„šæœ¬ç”Ÿæˆï¼ˆä¸éœ€è¦é¢„è®­ç»ƒæƒé‡ï¼‰
```

---

## æ­¥éª¤2ï¼šåŸºçº¿è®­ç»ƒï¼ˆ2å°æ—¶ï¼‰

### 2.1 Gen1 åŸºçº¿ï¼ˆ1% æ ‡æ³¨ï¼‰

```bash
# å•GPUè®­ç»ƒ
python train.py \
  model=rnndet \
  dataset=gen1x0.01_ss \
  +experiment/gen1="small.yaml" \
  hardware.gpus=0 \
  training.max_steps=200000 \
  batch_size.train=8 \
  batch_size.eval=8 \
  hardware.num_workers.train=8 \
  hardware.num_workers.eval=8

# é¢„æœŸè¾“å‡ºï¼š
# - æ—¥å¿—åœ¨ ./logs/gen1x0.01_ss/
# - æ£€æŸ¥ç‚¹åœ¨ ./ckpts/gen1x0.01_ss/last.ckpt
# - WandBæ—¥å¿—ï¼ˆå¦‚æœé…ç½®ï¼‰
```

**å…³é”®å‚æ•°è§£é‡Š**ï¼š
```yaml
model=rnndet                    # ä½¿ç”¨åŸºç¡€æ£€æµ‹å™¨ï¼ˆç¡¬é”šç‚¹ï¼‰
dataset=gen1x0.01_ss           # 1%æ ‡æ³¨æ•°æ®é›†
+experiment/gen1="small.yaml"  # RVT-Så¤§å°ï¼ˆembed_dim=64ï¼‰
training.max_steps=200000      # 200kæ­¥ç”¨äº1%æ•°æ®
```

**é¢„æœŸç»“æœ**ï¼š
```
Step 0:     mAP = 0%      (éšæœºåˆå§‹åŒ–)
Step 50k:   mAP â‰ˆ 15%     (å­¦ä¹ é˜¶æ®µ)
Step 100k:  mAP â‰ˆ 25%     (æ”¶æ•›)
Step 200k:  mAP â‰ˆ 28-30%  (æœ€ç»ˆ)
```

### 2.2 Gen4 åŸºçº¿ï¼ˆå¯é€‰ï¼Œæ›´å¤§çš„æ•°æ®é›†ï¼‰

```bash
# 2GPUè®­ç»ƒï¼ˆGen4æ•°æ®æ›´å¤§ï¼‰
python train.py \
  model=rnndet \
  dataset=gen4x0.01_ss \
  +experiment/gen4="small.yaml" \
  hardware.gpus=[0,1] \
  training.max_steps=200000 \
  batch_size.train=12 \
  hardware.num_workers.train=8

# é¢„æœŸï¼š~12-15% mAP
```

### 2.3 ç›‘æ§è®­ç»ƒè¿›åº¦

```bash
# å®æ—¶æŸ¥çœ‹
tail -f logs/gen1x0.01_ss/train.log

# æˆ–ä½¿ç”¨TensorBoard
tensorboard --logdir=./logs/

# WandBï¼ˆå¦‚æœæœ‰è´¦æˆ·ï¼‰
# åœ¨æµè§ˆå™¨æ‰“å¼€æç¤ºçš„é“¾æ¥å³å¯çœ‹å›¾è¡¨
```

---

## æ­¥éª¤3ï¼šç”Ÿæˆä¼ªæ ‡ç­¾ï¼ˆ7-10å°æ—¶ï¼‰

### 3.1 ç”Ÿæˆç¬¬1è½®ä¼ªæ ‡ç­¾

```bash
# ä½¿ç”¨åŸºçº¿æ¨¡å‹æ¨ç†æ‰€æœ‰äº‹ä»¶åºåˆ—
python predict.py \
  model=pseudo_labeler \
  dataset=gen1x0.01_ss \
  dataset.path=./datasets/gen1/ \
  checkpoint="./ckpts/gen1x0.01_ss/last.ckpt" \
  hardware.gpus=0 \
  hardware.num_workers.eval=8 \
  +experiment/gen1="small.yaml" \
  batch_size.eval=8 \
  model.postprocess.confidence_threshold=0.01 \
  tta.enable=True \
  save_dir=./datasets/pseudo_gen1/gen1x0.01_ss-1round/train

# è¿›åº¦æ¡ä¼šæ˜¾ç¤ºï¼š11376 it [~7h, ...]
```

**å‚æ•°è¯´æ˜**ï¼š
```yaml
tta.enable=True                          # 4å€æ¨ç†ï¼ˆTTAï¼‰
model.postprocess.confidence_threshold=0.01  # ä½é˜ˆå€¼ï¼ˆè·Ÿè¸ªè¿‡æ»¤ï¼‰
save_dir=...                             # ä¿å­˜ä½ç½®
```

**è¾“å‡ºç»“æ„**ï¼š
```
./datasets/pseudo_gen1/gen1x0.01_ss-1round/train/
â”œâ”€â”€ event_data.h5        (è½¯é“¾æ¥ï¼Œæ— é‡å¤å­˜å‚¨)
â”œâ”€â”€ gt_labels.npz        (å‚è€ƒç”¨)
â””â”€â”€ ä¼ªæ ‡ç­¾æ–‡ä»¶
    â”œâ”€â”€ sequence_0.npy
    â”œâ”€â”€ sequence_1.npy
    â””â”€â”€ ...
    
æ€»å¤§å°ï¼š100-150 MBï¼ˆvsåŸå§‹250 MBäº‹ä»¶æ•°æ®ï¼‰
```

### 3.2 (å¯é€‰) è¯„ä¼°ä¼ªæ ‡ç­¾è´¨é‡

```bash
# æŸ¥çœ‹ä¼ªæ ‡ç­¾çš„ç²¾åº¦/å¬å›
python val_dst.py \
  model=pseudo_labeler \
  dataset=gen1x0.01_ss \
  dataset.path=./datasets/pseudo_gen1/gen1x0.01_ss-1round \
  checkpoint=1 \
  +experiment/gen1="small.yaml" \
  model.pseudo_label.obj_thresh=0.01 \
  model.pseudo_label.cls_thresh=0.01

# é¢„æœŸè¾“å‡ºï¼š
# Precision: 0.85-0.90  (å¥½çš„ä¼ªæ ‡ç­¾)
# Recall: 0.70-0.80
# å¦‚æœPrecision < 0.80ï¼Œè¯´æ˜ä¼ªæ ‡ç­¾å¤ªå˜ˆæ‚
```

### 3.3 Gen4ä¼ªæ ‡ç­¾ï¼ˆå¯é€‰ï¼‰

```bash
python predict.py \
  model=pseudo_labeler \
  dataset=gen4x0.01_ss \
  dataset.path=./datasets/gen4/ \
  checkpoint="./ckpts/gen4x0.01_ss/last.ckpt" \
  +experiment/gen4="small.yaml" \
  tta.enable=True \
  save_dir=./datasets/pseudo_gen4/gen4x0.01_ss-1round/train

# è€—æ—¶æ›´ä¹…ï¼ˆæ•°æ®æ›´å¤§ï¼‰ï¼š~10-12å°æ—¶
```

---

## æ­¥éª¤4ï¼šè‡ªè®­ç»ƒç¬¬1è½®ï¼ˆ2å°æ—¶ï¼‰

### 4.1 åˆ›å»ºä¼ªæ ‡ç­¾æ•°æ®é›†é…ç½®

**åˆ›å»ºæ–‡ä»¶**ï¼š`config/dataset/gen1x0.01_ss-1round.yaml`

```yaml
defaults: []

name: gen1
path: ./datasets/pseudo_gen1/gen1x0.01_ss-1round/train/

downsample_by_factor_2: False
sequence_length: 10

# å…³é”®ï¼šä½¿ç”¨æ‰€æœ‰ä¼ªæ ‡ç­¾ï¼ˆä¸å­é‡‡æ ·ï¼‰
ratio: -1

seed: 42

train:
  sampling: 'mixed'  # ä»ç„¶æ··åˆé‡‡æ ·
  random:
    weighted_sampling: False
  mixed:
    w_stream: 1
    w_random: 1

eval:
  sampling: 'stream'
```

### 4.2 åœ¨ä¼ªæ ‡ç­¾ä¸Šè®­ç»ƒ

```bash
# ç¬¬1è½®è‡ªè®­ç»ƒ
python train.py \
  model=rnndet-soft \
  dataset=gen1x0.01_ss-1round \
  +experiment/gen1="small.yaml" \
  hardware.gpus=0 \
  training.max_steps=150000 \
  training.learning_rate=0.0005 \
  batch_size.train=8 \
  batch_size.eval=8

# å…³é”®å˜åŒ–ï¼š
# - model=rnndet-soft (è½¯é”šç‚¹ï¼Œå®¹å¿ä¼ªæ ‡ç­¾å™ªå£°)
# - training.max_steps=150000 (æ›´å°‘æ­¥æ•°ï¼Œæ ‡ç­¾æ›´å¯†é›†)
# - training.learning_rate=0.0005 (æ›´é«˜å­¦ä¹ ç‡ï¼Œæ”¶æ•›æ›´å¿«)

# é¢„æœŸç»“æœï¼š
# Step 50k:   mAP â‰ˆ 32%
# Step 100k:  mAP â‰ˆ 36%
# Step 150k:  mAP â‰ˆ 37.6% (+30% ç›¸æ¯”åŸºçº¿ï¼)
```

**ä¸ºä»€ä¹ˆå‚æ•°ä¸åŒï¼Ÿ**
```
åŸºçº¿ï¼ˆGround Truthç¨€ç–ï¼‰:
- æ ‡ç­¾å°‘ï¼Œå­¦ä¹ æ…¢ â†’ éœ€è¦200kæ­¥
- é”™è¯¯æ ‡ç­¾å¾ˆå°‘ â†’ ç¡¬ç›®æ ‡ï¼ˆexact matchï¼‰

ä¼ªæ ‡ç­¾ï¼ˆç¨€ç–æ€§ä¸­ç­‰ï¼‰:
- æ ‡ç­¾æ›´å¤šï¼Œå­¦ä¹ æ›´å¿« â†’ 150kæ­¥è¶³å¤Ÿ
- å¯èƒ½æœ‰å°é”™è¯¯ â†’ è½¯ç›®æ ‡ï¼ˆå®¹å¿è¯¯å·®ï¼‰
```

### 4.3 ç›‘æ§æ”¹è¿›

```bash
# æ¯”è¾ƒmAPè¿›å±•
echo "åŸºçº¿:    28.5% mAP"
echo "ç¬¬1è½®:   37.6% mAP"
echo "æ”¹è¿›:    +30%ï¼"

# WandB / TensorBoardæŸ¥çœ‹è¯¦ç»†æ›²çº¿
tensorboard --logdir=./logs/
```

---

## æ­¥éª¤5ï¼šæœ€ç»ˆè¯„ä¼°ï¼ˆ1å°æ—¶ï¼‰

### 5.1 åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°

```bash
# ä½¿ç”¨æœ€å¥½çš„æ£€æŸ¥ç‚¹
python val.py \
  model=rnndet \
  dataset=gen1 \
  dataset.path=./datasets/gen1/ \
  checkpoint="./ckpts/gen1x0.01_ss-1round/last.ckpt" \
  use_test_set=1 \
  hardware.gpus=0 \
  hardware.num_workers.eval=8 \
  +experiment/gen1="small.yaml" \
  batch_size.eval=16 \
  model.postprocess.confidence_threshold=0.001 \
  reverse=False \
  tta.enable=False

# è€—æ—¶ï¼š~20-30åˆ†é’Ÿ
# è¾“å‡ºæœ€ç»ˆmAPå’Œè¯¦ç»†æŒ‡æ ‡
```

**é¢„æœŸè¾“å‡º**ï¼š
```
============ è¯„ä¼°ç»“æœ ============
mAP:         37.6%
mAP@IoU=0.5: 57.3%
mAP@IoU=0.75: 42.1%
AR:          0.68

å¯¹æ¯”ï¼š
åŸºçº¿ï¼ˆ1%æ ‡æ³¨ï¼‰: 28.5% â†’ 57% æ”¹è¿›
å®Œå…¨ç›‘ç£:       38.6% â†’ 97.4% å…³é—­å·®è·
```

### 5.2 å¯è§†åŒ–é¢„æµ‹ç»“æœ

```bash
# ç”Ÿæˆæ£€æµ‹ç»“æœè§†é¢‘
python vis_pred.py \
  model=rnndet \
  dataset=gen1 \
  dataset.path=./datasets/gen1/ \
  checkpoint="./ckpts/gen1x0.01_ss-1round/last.ckpt" \
  +experiment/gen1="small.yaml" \
  model.postprocess.confidence_threshold=0.1 \
  num_video=5 \
  reverse=False

# è¾“å‡ºï¼š./vis/gen1_rnndet_small/pred/*.mp4
# é»‘æ¡†=GTï¼Œç»¿æ¡†=é¢„æµ‹
```

---

## æ­¥éª¤6ï¼š(å¯é€‰) ç¬¬2è½®è‡ªè®­ç»ƒ

### 6.1 ç¬¬2è½®ä¼ªæ ‡ç­¾

```bash
# ç”¨æ”¹è¿›çš„æ¨¡å‹ç”Ÿæˆæ–°ä¼ªæ ‡ç­¾
python predict.py \
  model=pseudo_labeler \
  dataset=gen1x0.01_ss \
  dataset.path=./datasets/gen1/ \
  checkpoint="./ckpts/gen1x0.01_ss-1round/last.ckpt" \
  tta.enable=True \
  save_dir=./datasets/pseudo_gen1/gen1x0.01_ss-2round/train

# åˆ›å»ºconfig: config/dataset/gen1x0.01_ss-2round.yaml
# (å¤åˆ¶gen1x0.01_ss-1round.yamlï¼Œä¿®æ”¹path)
```

### 6.2 ç¬¬2è½®è®­ç»ƒ

```bash
# é¢„æœŸï¼š+0.6% æ”¹è¿›ï¼ˆæ”¶ç›Šé€’å‡ï¼‰
python train.py \
  model=rnndet-soft \
  dataset=gen1x0.01_ss-2round \
  +experiment/gen1="small.yaml" \
  training.max_steps=150000 \
  training.learning_rate=0.0005

# æœ€ç»ˆï¼š37.6% â†’ 38.2% mAP
```

---

## å®Œæ•´æ£€æŸ¥æ¸…å•

```
âœ“ ç¬¬1é˜¶æ®µï¼šç¯å¢ƒ
  âœ“ Condaç¯å¢ƒåˆ›å»º
  âœ“ PyTorch/Lightningå®‰è£…
  âœ“ æ•°æ®é›†ä¸‹è½½
  
âœ“ ç¬¬2é˜¶æ®µï¼šåŸºçº¿
  âœ“ python train.py ... (2h)
  âœ“ éªŒè¯è¾“å‡º ./ckpts/gen1x0.01_ss/last.ckpt
  âœ“ æœŸæœ› mAP ~28-30%
  
âœ“ ç¬¬3é˜¶æ®µï¼šä¼ªæ ‡ç­¾
  âœ“ python predict.py ... (7-10h)
  âœ“ éªŒè¯è¾“å‡º ./datasets/pseudo_gen1/...
  âœ“ æ£€æŸ¥å¤§å° 100-150 MB
  âœ“ (å¯é€‰) è¯„ä¼°ç²¾åº¦
  
âœ“ ç¬¬4é˜¶æ®µï¼šè‡ªè®­ç»ƒ
  âœ“ åˆ›å»º config/dataset/gen1x0.01_ss-1round.yaml
  âœ“ python train.py model=rnndet-soft ... (2h)
  âœ“ æœŸæœ› mAP ~37.6% (+30%)
  
âœ“ ç¬¬5é˜¶æ®µï¼šè¯„ä¼°
  âœ“ python val.py ... (1h)
  âœ“ æŸ¥çœ‹æœ€ç»ˆæŒ‡æ ‡
  âœ“ (å¯é€‰) python vis_pred.py çœ‹è§†é¢‘
  
âœ“ (å¯é€‰) ç¬¬6é˜¶æ®µï¼šç¬¬2è½®
  âœ“ ç”Ÿæˆæ–°ä¼ªæ ‡ç­¾
  âœ“ å†è®­ç»ƒä¸€æ¬¡
  âœ“ æœŸæœ› mAP ~38.2%
```

---

## å¸¸è§é—®é¢˜ä¸å¿«é€Ÿè§£å†³

### Q1ï¼šæ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

```bash
# å‡å°‘æµå¼é‡‡æ ·æ¯”ä¾‹
python train.py \
  ... \
  dataset.train.mixed.w_stream=0.5 \
  dataset.train.mixed.w_random=1.0
# ç»“æœï¼š33% æµå¼ + 67% éšæœºï¼ŒèŠ‚çœ~30% æ˜¾å­˜
```

### Q2ï¼šè®­ç»ƒå¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

```bash
# å¢åŠ å·¥ä½œè¿›ç¨‹
python train.py \
  ... \
  hardware.num_workers.train=16  # ä»8æé«˜
# æˆ–å¢åŠ æ‰¹å¤§å°
batch_size.train=16
```

### Q3ï¼šä¼ªæ ‡ç­¾è´¨é‡ä¸å¥½æ€ä¹ˆåŠï¼Ÿ

```bash
# æŸ¥çœ‹ç²¾åº¦
python val_dst.py ... # Precision < 0.80?

# æé«˜è¿‡æ»¤é˜ˆå€¼é‡æ–°ç”Ÿæˆ
python predict.py \
  ... \
  model.pseudo_label.obj_thresh=0.05 \
  model.pseudo_label.cls_thresh=0.05 \
  model.pseudo_label.filter.min_track_len=8
```

### Q4ï¼šç¬¬1è½®åmAPåè€Œä¸‹é™ï¼Ÿ

```bash
# è¯´æ˜ä¼ªæ ‡ç­¾å¤ªå˜ˆæ‚
# æ–¹æ¡ˆ1ï¼šé™ä½å­¦ä¹ ç‡
training.learning_rate=0.0002  # ä»0.0005é™ä½

# æ–¹æ¡ˆ2ï¼šå‡å°‘ä¼ªæ ‡ç­¾æƒé‡
model.pseudo_label.soft_label_weight=0.3  # æ›´ä¿¡ä»»GT

# æ–¹æ¡ˆ3ï¼šé‡æ–°ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œæ›´ä¸¥æ ¼è¿‡æ»¤
```

---

## æ€§èƒ½å¯¹æ ‡

**è®ºæ–‡ç»“æœ vs å®é™…å¤ç°**ï¼š

| æ•°æ®é›† | åŸºçº¿ | ç¬¬1è½® | ç¬¬2è½® | å®Œå…¨ç›‘ç£ |
|------|------|------|------|--------|
| **Gen1** | 28.5% | 37.6% | 38.2% | 38.6% |
| **Gen4** | 12.3% | 20.5% | 21.8% | 28.1% |

**æ”¹è¿›ç‡**ï¼š
```
Gen1: (37.6 - 28.5) / (38.6 - 28.5) = 91% å…³é—­å·®è·
Gen4: (20.5 - 12.3) / (28.1 - 12.3) = 52% å…³é—­å·®è·
```

---

## æ€»ç»“

ğŸ¯ **å…³é”®è¦ç‚¹**ï¼š

1. **åŸºçº¿**ï¼šåœ¨1%æ ‡æ³¨æ•°æ®ä¸Šè®­ç»ƒ â†’ ~28% mAP
2. **ä¼ªæ ‡ç­¾**ï¼šä½¿ç”¨TTA+è·Ÿè¸ªç”Ÿæˆé«˜è´¨é‡æ ‡ç­¾ â†’ 100-150 MB
3. **è‡ªè®­ç»ƒ**ï¼šåœ¨æ··åˆæ ‡ç­¾ä¸Šé‡æ–°è®­ç»ƒ â†’ ~37.6% mAP
4. **ç»“æœ**ï¼šç”¨ä»…1%çš„æ ‡ç­¾è¾¾åˆ°æ¥è¿‘100%æ ‡ç­¾çš„æ€§èƒ½ï¼

â±ï¸ **æ€»è€—æ—¶**ï¼š12-14å°æ—¶ï¼ˆGPUæ—¶é—´ï¼‰

ğŸš€ **å¼€å§‹å§ï¼** æŒ‰æ­¥éª¤æ‰§è¡Œï¼Œæ‚¨ä¹Ÿèƒ½å¤ç°SOTAç»“æœï¼

