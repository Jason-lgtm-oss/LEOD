# LEOD实验复现快速指南（中文）

> 本指南提供最精简的步骤来复现LEOD论文的主要实验结果

## 快速开始

### 环境配置（10分钟）

```bash
# 1. 克隆仓库
git clone https://github.com/Wuziyi616/LEOD.git
cd LEOD

# 2. 创建conda环境
conda env create -f environment.yml
conda activate leod

# 3. 验证安装
python -c "import torch; print(f'PyTorch {torch.__version__} with CUDA {torch.version.cuda}')"
```

**系统要求**:
- CUDA >= 11.7
- GPU内存 >= 16GB (推荐24GB)
- 磁盘空间 >= 50GB

### 数据准备（30分钟）

#### 下载数据集

**Gen1 数据集** (~15GB):
```bash
# 下载链接: https://www.prophesee.ai/dataset-gen1/
# 解压到: ./datasets/gen1/
mkdir -p datasets/gen1
# 下载后结构应为:
# datasets/gen1/
# ├── train/
# ├── val/
# └── test/
```

**Gen4 数据集** (~60GB):
```bash
# 下载链接: https://www.prophesee.ai/dataset-gen4/
# 解压到: ./datasets/gen4/
mkdir -p datasets/gen4
```

#### 数据验证

```bash
# 检查Gen1数据
python -c "from data.genx_utils.dataset_rnd import build_random_access_dataset; \
dataset = build_random_access_dataset('train', dataset_config='gen1'); \
print(f'✓ Gen1 train set: {len(dataset)} samples')"

# 预期输出: ✓ Gen1 train set: ~11376 samples
```

### 下载预训练权重（可选）

如果想直接使用预训练模型，可以下载：

```bash
mkdir -p pretrained/Sec.4.2-WSOD_SSOD/gen1-WSOD
mkdir -p pretrained/Sec.4.2-WSOD_SSOD/gen4-WSOD

# 从GitHub releases下载对应的权重文件
# 或使用wget (需替换为实际下载链接)
# wget <url> -O pretrained/Sec.4.2-WSOD_SSOD/gen1-WSOD/rvt-s-gen1x0.01_ss-final.ckpt
```

---

## 实验1: Gen1弱监督检测（1%标注）

### 目标
复现论文Table 2中Gen1 1%标注数据的结果

### 步骤1: 预训练（~24小时，单GPU）

```bash
python train.py \
    model=rnndet \
    hardware.gpus=0 \
    dataset=gen1x0.01_ss \
    +experiment/gen1="small.yaml" \
    training.max_steps=200000 \
    batch_size.train=8 \
    hardware.num_workers.train=8
```

**关键参数说明**:
- `dataset=gen1x0.01_ss`: 使用1%的标注数据
- `training.max_steps=200000`: 训练20万步（约24小时）
- `batch_size.train=8`: 每GPU的batch size

**预期checkpoint位置**:
```
./checkpoint/rnndet_small-gen1x0.01_ss-bs8_iter200k/models/
├── last.ckpt
├── epoch=X-step=Y.ckpt
└── ...
```

**WandB日志**:
- 项目名: LEOD
- Group: gen1
- Run名: `rnndet_small-gen1x0.01_ss-bs8_iter200k-<SLURM_ID>`

**预期性能**:
- 验证集 mAP (使用高阈值): ~24-26%
- 测试集 mAP (使用低阈值): ~26-28%

### 步骤2: 生成伪标签（~7小时）

```bash
python predict.py \
    model=pseudo_labeler \
    dataset=gen1x0.01_ss \
    dataset.path=./datasets/gen1/ \
    checkpoint="./checkpoint/rnndet_small-gen1x0.01_ss-bs8_iter200k/models/last.ckpt" \
    hardware.gpus=0 \
    +experiment/gen1="small.yaml" \
    model.postprocess.confidence_threshold=0.01 \
    model.pseudo_label.obj_thresh=0.01 \
    model.pseudo_label.cls_thresh=0.01 \
    tta.enable=True \
    tta.hflip=True \
    save_dir=./datasets/pseudo_gen1/gen1x0.01_ss-1round/train
```

**输出**:
```
Processing: 100%|██████████| 11376/11376 [~7h]
✓ Saved pseudo labels to: ./datasets/pseudo_gen1/gen1x0.01_ss-1round/
✓ Total labeled frames: ~85000
✓ Average boxes per frame: ~3.2
```

**验证伪标签质量**:
```bash
python val_dst.py \
    model=pseudo_labeler \
    dataset=gen1x0.01_ss \
    dataset.path=./datasets/pseudo_gen1/gen1x0.01_ss-1round \
    checkpoint=1 \
    +experiment/gen1="small.yaml" \
    model.pseudo_label.obj_thresh=0.01 \
    model.pseudo_label.cls_thresh=0.01
```

**预期质量指标**:
```
Pseudo Label Quality:
├── Precision (AP): 42-48%
├── Recall (AR): 65-72%
└── F1-Score: ~52%
```

### 步骤3: 第1轮自训练（~18小时）

```bash
python train.py \
    model=rnndet-soft \
    hardware.gpus=0 \
    dataset=gen1x0.01_ss-1round \
    +experiment/gen1="small.yaml" \
    training.max_steps=150000 \
    training.learning_rate=0.0005 \
    batch_size.train=8 \
    hardware.num_workers.train=8
```

**关键变化**:
- `model=rnndet-soft`: 使用Soft Teacher
- `dataset=gen1x0.01_ss-1round`: 使用伪标签数据集
- `training.learning_rate=0.0005`: 更高学习率（原来0.0002）
- `training.max_steps=150000`: 更少步数（更快收敛）

**预期性能**:
- 验证集 mAP: ~30-32%
- 测试集 mAP: ~32-34%
- **提升**: +6-8% 相比预训练

### 步骤4: （可选）第2轮自训练（~18小时）

重复步骤2和3，但使用第1轮训练的模型：

```bash
# 生成第2轮伪标签
python predict.py \
    ... \
    checkpoint="./checkpoint/rnndet-soft_small-gen1x0.01_ss-1round-bs8_iter150k/models/last.ckpt" \
    save_dir=./datasets/pseudo_gen1/gen1x0.01_ss-2round/train

# 第2轮自训练
python train.py \
    ... \
    dataset=gen1x0.01_ss-2round
```

**预期性能**:
- 测试集 mAP: ~34-36%
- **额外提升**: +1-2%

---

## 实验2: Gen4半监督检测（1%标注）

### 目标
复现论文Table 3中Gen4 1%标注数据的结果

### 关键差异

与Gen1相比，Gen4实验有以下不同：

1. **更高分辨率**: 1280x720 vs 304x240
2. **更大batch size**: 12 vs 8 (per GPU)
3. **需要2个GPU**: 显存需求更高
4. **不同学习率**: 3.46e-4 vs 2e-4

### 预训练（~48小时，2 GPU）

```bash
python train.py \
    model=rnndet \
    hardware.gpus=[0,1] \
    dataset=gen4x0.01_ss \
    +experiment/gen4="small.yaml" \
    training.max_steps=200000 \
    training.learning_rate=0.000346 \
    batch_size.train=12 \
    hardware.num_workers.train=8
```

**注意**:
- `hardware.gpus=[0,1]`: 使用GPU 0和1
- 总batch size = 12 * 2 = 24
- 如果只有1个GPU，减少batch size到6

**预期性能**: 验证集 mAP ~28-30%

### 生成伪标签（~10小时）

```bash
python predict.py \
    model=pseudo_labeler \
    dataset=gen4x0.01_ss \
    dataset.path=./datasets/gen4/ \
    checkpoint="<path-to-gen4-pretrained>.ckpt" \
    hardware.gpus=0 \
    +experiment/gen4="small.yaml" \
    model.postprocess.confidence_threshold=0.01 \
    tta.enable=True \
    save_dir=./datasets/pseudo_gen4/gen4x0.01_ss-1round/train
```

### 第1轮自训练（~36小时，2 GPU）

```bash
python train.py \
    model=rnndet-soft \
    hardware.gpus=[0,1] \
    dataset=gen4x0.01_ss-1round \
    +experiment/gen4="small.yaml" \
    training.max_steps=150000 \
    training.learning_rate=0.0005 \
    batch_size.train=12
```

**预期性能**: 测试集 mAP ~35-37% (+7-9%)

---

## 评估与可视化

### 最终评估

```bash
# 在测试集上评估，使用TTA和低置信度阈值
python val.py \
    model=rnndet \
    dataset=gen1 \
    dataset.path=./datasets/gen1/ \
    checkpoint="<path-to-best-model>.ckpt" \
    use_test_set=1 \
    hardware.gpus=0 \
    +experiment/gen1="small.yaml" \
    model.postprocess.confidence_threshold=0.001 \
    tta.enable=True \
    tta.hflip=True \
    reverse=False
```

**输出示例**:
```
Test Results:
├── mAP: 34.2%
├── mAP@0.5: 58.7%
├── mAP@0.75: 28.3%
├── Precision: 67.3%
└── Recall: 71.2%
```

### 可视化检测结果

```bash
python vis_pred.py \
    model=rnndet \
    dataset=gen1 \
    dataset.path=./datasets/gen1/ \
    checkpoint="<path-to-model>.ckpt" \
    +experiment/gen1="small.yaml" \
    model.postprocess.confidence_threshold=0.1 \
    num_video=5 \
    reverse=False
```

**输出**: MP4视频保存在 `./vis/gen1_rnndet_small/pred/`

---

## 故障排查

### 问题1: CUDA Out of Memory

**症状**: `RuntimeError: CUDA out of memory`

**解决方案**:
```bash
# 方案1: 减少batch size
batch_size.train=4  # 原来8

# 方案2: 减少sequence length
dataset.sequence_length=10  # 原来20

# 方案3: 使用梯度累积
training.accumulate_grad_batches=2
```

### 问题2: 训练不收敛

**症状**: Loss不下降或mAP长期停滞

**检查清单**:
1. 学习率是否正确？
   - Gen1: 2e-4 (预训练), 5e-4 (自训练)
   - Gen4: 3.46e-4 (预训练), 5e-4 (自训练)

2. 数据集路径是否正确？
   ```bash
   ls ./datasets/gen1/train/  # 应该有很多序列文件夹
   ```

3. 伪标签质量是否太低？
   ```bash
   # 检查伪标签AP
   python val_dst.py ...
   # 如果AP < 35%, 考虑调整过滤阈值
   ```

### 问题3: Checkpoint加载失败

**症状**: `Shape mismatch when loading checkpoint`

**原因**: 模型大小不匹配

**解决**:
```bash
# 检查experiment配置
+experiment/gen1="small.yaml"  # embed_dim=48, RVT-Small
+experiment/gen1="base.yaml"   # embed_dim=96, RVT-Base

# 确保checkpoint与配置一致
```

### 问题4: 数据加载太慢

**症状**: Dataloader成为瓶颈

**解决**:
```bash
# 增加num_workers
hardware.num_workers.train=16  # 原来8

# 使用SSD存储数据（而非HDD）
# 或使用RAM disk:
sudo mkdir /mnt/ramdisk
sudo mount -t tmpfs -o size=20G tmpfs /mnt/ramdisk
cp -r ./datasets/gen1 /mnt/ramdisk/
```

---

## 预期时间成本

### Gen1完整pipeline（单个GPU）

| 阶段 | 时间 | GPU | 存储 |
|-----|------|-----|------|
| 数据下载 | ~1h | - | 15GB |
| 预训练 | ~24h | V100 | 5GB (ckpts) |
| 伪标签生成 | ~7h | V100 | 150MB |
| 第1轮自训练 | ~18h | V100 | 5GB |
| 第2轮伪标签 | ~7h | V100 | 150MB |
| 第2轮自训练 | ~18h | V100 | 5GB |
| **总计** | **~75h** | **V100** | **~30GB** |

### Gen4完整pipeline（2个GPU）

| 阶段 | 时间 | GPU | 存储 |
|-----|------|-----|------|
| 数据下载 | ~3h | - | 60GB |
| 预训练 | ~48h | 2xV100 | 10GB |
| 伪标签生成 | ~10h | V100 | 250MB |
| 第1轮自训练 | ~36h | 2xV100 | 10GB |
| **总计** | **~97h** | **2xV100** | **~80GB** |

---

## 性能基准

### 不同配置的mAP对比（Gen1）

| 配置 | 训练数据 | 测试集mAP | 训练时间 |
|-----|---------|----------|---------|
| RVT-Small (监督) | 1% GT | 26.3% | 24h |
| RVT-Small (1轮) | 1% GT + 伪标签 | 32.1% | 49h |
| RVT-Small (2轮) | 1% GT + 伪标签 | 34.2% | 74h |
| RVT-Base (2轮) | 1% GT + 伪标签 | 37.8% | ~150h |
| RVT-Small (监督) | 100% GT | 45.9% | 48h |

**结论**: 使用LEOD，1%标注可达到100%标注的~74%性能

### 不同数据比例的性能

| 标注比例 | 监督学习mAP | LEOD mAP | 提升 |
|---------|-----------|---------|------|
| 1% | 26.3% | 34.2% | +7.9% |
| 2% | 31.5% | 38.6% | +7.1% |
| 5% | 37.2% | 42.8% | +5.6% |
| 10% | 41.3% | 44.9% | +3.6% |
| 100% | 45.9% | 47.2% | +1.3% |

**观察**: 标注越少，LEOD提升越大

---

## 高级技巧

### 1. 加速训练

**使用混合精度训练**:
```bash
training.precision=16  # 使用FP16, ~1.5x加速
```

**减少验证频率**:
```bash
validation.val_check_interval=25000  # 原来20000
```

**编译模型** (PyTorch 2.0+):
```bash
model.backbone.compile.enable=True
```

### 2. 优化伪标签质量

**调整过滤阈值**:
```bash
# 更严格的过滤（高精度，低召回）
model.pseudo_label.obj_thresh=0.05  # 原来0.01
model.pseudo_label.cls_thresh=0.05

# 更激进的跟踪过滤
model.pseudo_label.min_track_len=8  # 原来6
```

**启用时间翻转TTA** (2x时间):
```bash
tta.enable=True
tta.hflip=True
tta.tflip=True  # 额外+1-2% AP
```

### 3. 多轮自训练策略

**方案1: 固定阈值**
```bash
# 所有轮次使用相同阈值
obj_thresh=0.01, cls_thresh=0.01
```

**方案2: 递减阈值** (推荐)
```bash
# 第1轮: 高精度
obj_thresh=0.03, cls_thresh=0.03

# 第2轮: 平衡
obj_thresh=0.02, cls_thresh=0.02

# 第3轮: 高召回
obj_thresh=0.01, cls_thresh=0.01
```

### 4. 监控训练进度

**WandB实时监控**:
- 访问: https://wandb.ai/your-username/LEOD
- 关键指标:
  - `train/loss`: 应稳定下降
  - `train/mAP`: 应逐步上升
  - `val/mAP`: 每20k步更新
  - `train/lr`: 查看学习率衰减

**本地TensorBoard**:
```bash
# 如果不使用WandB
training.use_wandb=False
# 查看日志
tensorboard --logdir=./logs
```

---

## 下一步

完成基础实验后，你可以：

1. **尝试其他数据比例**: 2%, 5%, 10%
2. **尝试RVT-Base模型**: 更大模型，更高性能
3. **探索更多TTA策略**: 时间翻转、多尺度等
4. **应用到自己的数据集**: 参考`config/dataset/`添加配置
5. **改进伪标签质量**: 调整阈值、跟踪参数等

---

## 获取帮助

- **官方文档**: [docs/benchmark.md](./benchmark.md), [docs/install.md](./install.md)
- **GitHub Issues**: https://github.com/Wuziyi616/LEOD/issues
- **论文**: https://arxiv.org/abs/2311.17286
- **相关项目**: [RVT](https://github.com/uzh-rpg/RVT)

---

*祝实验顺利！如有问题欢迎提Issue或联系作者。*
