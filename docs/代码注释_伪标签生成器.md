# 伪标签生成器模块详解（modules/pseudo_labeler.py）

> 本文档提供`modules/pseudo_labeler.py`的详细中文注释和讲解

## 模块概述

`PseudoLabeler`是LEOD论文中伪标签生成的核心实现，继承自`Module`（检测模块），复用了检测逻辑并扩展了以下功能：

1. **Test-Time Augmentation (TTA)**: 水平翻转和时间翻转增强
2. **置信度过滤**: 双重阈值（objectness + class confidence）过滤
3. **基于跟踪的过滤**: 使用线性跟踪器过滤短轨迹和假阳性
4. **轨迹填充**: 为长轨迹的缺失帧填充bbox
5. **伪标签保存**: 以Prophesee格式保存，与原始数据集兼容

---

## 核心类和函数

### 1. `tta_postprocess` - TTA结果后处理

```python
def tta_postprocess(preds: List[ObjectLabels],
                    conf_thre: float = 0.7,
                    nms_thre: float = 0.45,
                    class_agnostic: bool = False) -> List[ObjectLabels]:
    """
    对TTA的多次预测应用NMS和置信度过滤
    
    参数:
        preds: 预测列表，每个是ObjectLabels对象
        conf_thre: 置信度阈值（objectness * class_conf）
        nms_thre: NMS的IoU阈值
        class_agnostic: 是否忽略类别做NMS
    
    返回:
        过滤并NMS后的预测列表
    
    工作流程:
        1. 对于每个预测框:
           - 计算综合置信度 = objectness * class_confidence
           - 过滤低于conf_thre的框
        2. 应用NMS去除重复检测
           - class-wise NMS: 每个类别独立做NMS
           - class-agnostic NMS: 所有类别一起做NMS
        3. 转换回ObjectLabels格式
    
    为什么需要这个函数？
        - TTA会产生多个预测（原图 + 翻转图）
        - 同一个物体可能被检测多次
        - NMS聚合这些重复检测，保留最佳结果
    """
```

**代码详解**:

```python
# 步骤1: 置信度过滤
obj_conf, class_conf = pred[:, 4], pred[:, 5]
conf_mask = ((obj_conf * class_conf) >= conf_thre)  # 双重置信度
detections = detections[conf_mask]

# 为什么是乘法？
# - objectness: 这里有物体的概率
# - class_conf: 这个物体是某类别的概率
# - 乘积: 这里有某类别物体的概率（贝叶斯规则）

# 步骤2: NMS
if class_agnostic:
    # 所有类别一起做NMS，适用于类别间IoU高的情况
    nms_out_index = ops.nms(
        detections[:, :4],              # bbox坐标
        detections[:, 4] * detections[:, 5],  # 综合置信度
        nms_thre,                       # IoU阈值
    )
else:
    # 每个类别独立做NMS，更常用
    nms_out_index = ops.batched_nms(
        detections[:, :4],              # bbox坐标
        detections[:, 4] * detections[:, 5],  # 综合置信度
        detections[:, 6],               # 类别ID
        nms_thre,
    )
```

### 2. `EventSeqData` - 事件序列数据管理

```python
class EventSeqData:
    """
    记录单个事件序列的所有预测标签
    
    职责:
        1. 累积模型在该序列上的所有预测（包括TTA）
        2. 聚合TTA结果（NMS）
        3. 应用跟踪过滤
        4. 保存最终的伪标签
    
    属性:
        path: 事件序列路径
        scale_ratio: 检测时的下采样比例（需要还原）
        frame_idx_2_labels: 字典 {帧索引: ObjectLabels}
        _eoe: 是否已到达序列末尾
        _aug: 是否应用了TTA
    
    为什么需要这个类？
        - 模型是逐batch推理的，需要累积整个序列的结果
        - TTA会对同一帧产生多次预测，需要聚合
        - 后处理（跟踪过滤、填充）需要完整序列信息
    """
```

#### 2.1 `update` - 更新预测

```python
def update(self, labels: List[ObjectLabels], ev_idx: List[int],
           is_last_sample: bool, is_padded_mask: List[bool],
           is_hflip: bool, is_tflip: bool, tflip_offset: int) -> None:
    """
    添加新的模型预测到序列
    
    参数:
        labels: 预测的ObjectLabels列表
        ev_idx: 对应的帧索引
        is_last_sample: 是否是序列的最后一个batch
        is_padded_mask: 哪些是padding的
        is_hflip: 是否是水平翻转的预测
        is_tflip: 是否是时间翻转的预测
        tflip_offset: 时间翻转的偏移量
    
    逻辑:
        1. 如果is_hflip=True，先翻转回原坐标系
        2. 如果is_tflip=True，调整帧索引
        3. 累积到frame_idx_2_labels字典
        4. 同一帧的多次预测会被合并（后续做NMS）
    """
    self._eoe = is_last_sample
    
    # 处理水平翻转
    if is_hflip:
        labels = self._hflip_bbox(labels)  # 翻转回原坐标
        self._aug = True
    
    # 处理时间翻转
    if is_tflip:
        ev_idx = [i + tflip_offset for i in ev_idx]
        self._aug = True
    
    # 累积预测
    self._update(labels, ev_idx, is_padded_mask)
```

#### 2.2 `_track` - 基于跟踪的过滤

```python
@staticmethod
def _track(labels: List[ObjectLabels],
           frame_idx: List[int],
           min_track_len: int = 6,
           inpaint: bool = False) -> List[int]:
    """
    使用线性跟踪器过滤短轨迹的检测
    
    核心思想:
        真实物体应该形成较长的时间轨迹
        短轨迹（<6帧）通常是假阳性或遮挡物体
    
    参数:
        labels: ObjectLabels列表
        frame_idx: 对应的帧索引
        min_track_len: 最小轨迹长度（默认6）
        inpaint: 是否填充缺失帧
    
    返回:
        remove_idx: 要删除的bbox索引列表
        inpainted_bbox: 填充的bbox字典 {帧索引: bbox}
    
    算法流程:
        1. 初始化线性跟踪器
        2. 对每一帧调用tracker.update()
           - 有标签的帧: 传入检测框
           - 无标签的帧: 空更新（维护跟踪状态）
        3. tracker.finish() 完成所有轨迹
        4. 遍历每个bbox，检查其轨迹长度
           - hits >= min_track_len: 保留
           - hits < min_track_len: 标记删除
        5. (可选) 为长轨迹填充缺失帧
    """
    
    # 步骤1: 初始化跟踪器
    model = LinearTracker(img_hw=labels[0].input_size_hw)
    
    # 步骤2: 逐帧更新跟踪器
    for f_idx in range(max(frame_idx) + 1):
        if f_idx not in frame_idx:
            model.update(f_idx)  # 空帧也要更新
            continue
        
        # 获取该帧的检测
        idx = frame_idx.index(f_idx)
        obj_label: ObjectLabels = labels[idx]
        
        # 转换为tracker需要的格式: [x,y,w,h,cls_id]
        bboxes = obj_label.get_xywh(format_='center', add_class_id=True)
        is_gt = obj_label.is_gt_label()
        
        # 更新跟踪器（关联+预测）
        model.update(frame_idx=f_idx, dets=bboxes, is_gt=is_gt)
    
    # 步骤3: 完成跟踪
    model.finish()
    
    # 步骤4: 根据轨迹长度过滤
    bbox_idx, remove_idx = 0, []
    for obj_label in labels:
        for _ in range(len(obj_label)):
            tracker = model.get_bbox_tracker(bbox_idx)
            # 保留条件: 未完成 OR GT OR 轨迹够长
            if (not tracker.done) or tracker.is_gt or \
                    tracker.hits >= min_track_len:
                pass  # 保留
            else:
                remove_idx.append(bbox_idx)  # 删除
            bbox_idx += 1
    
    # 步骤5: (可选) 填充缺失帧
    if inpaint:
        inpainted_bbox = {}
        for tracker in model.prev_trackers:
            # 只为长轨迹填充
            if tracker.hits >= min_track_len:
                for f_idx, bbox in tracker.missed_bbox.items():
                    if f_idx not in inpainted_bbox:
                        inpainted_bbox[f_idx] = []
                    inpainted_bbox[f_idx].append(bbox)
        return remove_idx, inpainted_bbox
    
    return remove_idx, {}
```

**为什么这个方法有效？**

1. **时间一致性**: 真实物体在连续帧中应该被持续检测到
2. **减少假阳性**: 单帧的误检测不会形成长轨迹
3. **处理遮挡**: 长轨迹即使部分帧缺失也会被保留
4. **数据增强**: 填充缺失帧增加标注密度

**示例**:

```
帧序列: 0  1  2  3  4  5  6  7  8  9
物体A:  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  ✓  (轨迹长度10, 保留)
物体B:  ✓  ✓  ✓  -  -  ✓  ✓  ✓  ✓  ✓  (轨迹长度8, 保留, 填充帧3-4)
物体C:  ✓  ✓  ✓  -  -  -  -  -  -  -  (轨迹长度3, 删除, 可能是误检)
```

#### 2.3 `_track_filter` - 双向跟踪过滤

```python
def _track_filter(self) -> None:
    """
    应用双向跟踪过滤（前向 + 后向）
    
    为什么需要双向？
        - 前向跟踪: 物体从左到右/上到下移动
        - 后向跟踪: 物体从右到左/下到上移动
        - 双向都认为是短轨迹的才删除（更保守）
    
    track_method选项:
        - 'forward': 只做前向跟踪
        - 'forward or backward': 双向跟踪，取交集
    
    逻辑:
        1. 前向跟踪，得到remove_idx_fwd
        2. (可选) 后向跟踪，得到remove_idx_bwd
        3. 取交集: 两个方向都要删除的才删除
        4. 标记删除: 设class_id=1024（而非真删除）
        5. 填充缺失帧
    """
    
    min_track_len = self.filter_config.min_track_len
    if min_track_len <= 0:
        return  # 跳过跟踪过滤
    
    # 前向跟踪
    remove_idx, inpainted_bbox = self._track(
        self.labels,
        self.frame_idx,
        min_track_len=min_track_len,
        inpaint=self.filter_config.inpaint
    )
    
    # 后向跟踪 (可选)
    track_method = self.filter_config.track_method
    if 'backward' in track_method:
        # 翻转标签和索引
        rev_labels = [label.get_reverse() for label in self.labels[::-1]]
        rev_frame_idx = [max(self.frame_idx) - idx for idx in self.frame_idx[::-1]]
        
        bg_remove_idx, _ = self._track(
            rev_labels, rev_frame_idx,
            min_track_len=min_track_len,
            inpaint=False  # 只前向填充
        )
        
        # 翻转回原索引
        nlabels = sum(len(label) for label in self.labels)
        bg_remove_idx = [nlabels - idx - 1 for idx in bg_remove_idx[::-1]]
        
        # 取交集: 两个方向都删除的才删除
        remove_idx = list(set(remove_idx) & set(bg_remove_idx))
    
    # 标记删除（设class_id=1024）
    bbox_idx = 0
    for idx, obj_label in enumerate(self.labels):
        new_class_id = copy.deepcopy(obj_label.class_id)
        for i in range(len(obj_label)):
            if bbox_idx in remove_idx:
                new_class_id[i] = 1024  # ignore_label
                assert obj_label.is_pseudo_label().all()  # 确保不删GT
            bbox_idx += 1
        self.labels[idx].class_id = new_class_id
    
    # 填充缺失帧
    if inpainted_bbox:
        for f_idx, obj_label in inpainted_bbox.items():
            obj_label[:, 5] = 1024  # 填充的也标记ignore
            obj_label = ObjectLabels(obj_label, self.labels[0].input_size_hw)
            
            if f_idx in self.frame_idx:
                idx = self.frame_idx.index(f_idx)
                self.labels[idx] += obj_label  # 添加到现有标签
            else:
                self.frame_idx.append(f_idx)
                self.labels.append(obj_label)  # 新增标签帧
        
        # 重新排序
        self.labels = [label for _, label in sorted(zip(self.frame_idx, self.labels))]
        self.frame_idx = sorted(self.frame_idx)
```

**Ignore Label机制的优势**:

```python
# 方案1: 直接删除 (不推荐)
labels.pop(idx)  # 问题: 破坏索引, 难以追踪

# 方案2: 标记忽略 (LEOD采用)
labels[idx].class_id = 1024  # 保留结构, 训练时跳过

# 训练时的处理
if label.class_id == 1024:
    continue  # 不计算loss
```

#### 2.4 `save` - 保存伪标签

```python
def save(self, save_dir: str, dst_name: str) -> None:
    """
    保存伪标签数据集
    
    目录结构:
        save_dir/
        ├── train/
        │   └── <sequence_name>/
        │       ├── event_representations_v2/
        │       │   ├── event_representations.h5 (软链接)
        │       │   └── objframe_idx_2_repr_idx.npy
        │       └── labels_v2/
        │           └── labels.npz
        ├── val/ (软链接到原始val)
        └── test/ (软链接到原始test)
    
    为什么软链接？
        - 事件表示不需要重新生成（数百GB）
        - 只保存新的标签文件（数百MB）
        - 节省存储和计算时间
    
    labels.npz内容:
        - labels: [N, 8] structured array
          格式: [t, x, y, w, h, class_id, class_conf, objectness]
        - objframe_idx_2_label_idx: [M] array
          记录每个标注帧的标签起始索引
    """
    
    # 步骤1: 聚合TTA结果
    self._aggregate_results(num_frames=num_ev_repr)
    
    # 步骤2: 跟踪过滤
    self._track_filter()
    
    # 步骤3: 转换为numpy格式
    labels, objframe_idx_2_label_idx, objframe_idx_2_repr_idx = \
        self._summarize()
    
    # 步骤4: 软链接事件表示
    os.symlink(original_h5_path, new_h5_path)
    
    # 步骤5: 保存标签
    np.save(
        osp.join(new_ev_dir, 'objframe_idx_2_repr_idx.npy'),
        objframe_idx_2_repr_idx
    )
    np.savez(
        new_labels_npz_fn,
        labels=labels,
        objframe_idx_2_label_idx=objframe_idx_2_label_idx
    )
    
    # 步骤6: 软链接val/test
    os.symlink(original_val, new_val)
    os.symlink(original_test, new_test)
```

### 3. `PseudoLabeler` - 主类

```python
class PseudoLabeler(Module):
    """
    伪标签生成器，继承自检测模块
    
    主要扩展:
        1. TTA支持 (水平翻转、时间翻转)
        2. 伪标签质量评估
        3. 保存伪标签数据集
    
    使用方式:
        python predict.py model=pseudo_labeler ...
    """
```

#### 3.1 `__init__` - 初始化

```python
def __init__(self, *args, **kwargs):
    super().__init__(*args, **kwargs)
    
    # RNN状态管理 (继承自Module)
    self.mode_2_seq_lens = SeqLens()
    
    # 事件序列数据存储
    self.ev_path_2_ev_data: Dict[str, EventSeqData] = {}
    self.ev_cnt = 0
    
    # 数据集配置
    self.dst_name = self.dst_config.name  # 'gen1' or 'gen4'
    self.save_dir = self.full_config.save_dir
    
    # 是否使用GT标签 (Gen1=True, Gen4可选False)
    self.use_gt = self.full_config.get('use_gt', True)
    
    # TTA配置
    self.tta_cfg = self.full_config.tta
    
    # 质量评估指标
    self.metrics: Dict[str, AverageMeter] = {}
    self.results: Dict[str, List[float]] = {}
```

#### 3.2 `get_data_from_batch` - TTA数据准备

```python
def get_data_from_batch(self, batch: Any):
    """
    准备输入数据，应用TTA
    
    TTA处理:
        1. 原始输入: [L, B, C, H, W]
        2. 水平翻转: torch.flip(ev_repr, dims=[-1])
        3. 拼接: [L, 2B, C, H, W] (如果启用hflip)
        4. 复制其他数据项 (labels, idx, masks等)
    
    返回:
        data: 字典，包含所有需要的数据
        - EV_REPR: 事件表示 (可能2B)
        - OBJLABELS_SEQ: 标签序列
        - is_hflip: 标记哪些是翻转的
    """
    
    data = batch[DATA_KEY]
    ev_repr = th.stack(data[DataType.EV_REPR]).to(dtype=self.dtype)
    B = ev_repr.shape[1]
    data['is_hflip'] = np.array([False] * B, dtype=bool)
    
    # 应用水平翻转TTA
    if self.tta_cfg.enable and self.tta_cfg.hflip:
        hflip_ev_repr = th.flip(ev_repr, dims=[-1])  # 最后一维翻转
        ev_repr = th.cat([ev_repr, hflip_ev_repr], dim=1)  # 2B
        
        # 复制并翻转标签
        new_data = {}
        for k in (DataType.IS_FIRST_SAMPLE, DataType.IS_LAST_SAMPLE, ...):
            new_data[k] = th.cat([data[k]] * 2, dim=-1)
        
        for k in (DataType.OBJLABELS_SEQ, DataType.SKIPPED_OBJLABELS_SEQ):
            labels, labels_flip = data[k], copy.deepcopy(data[k])
            for i, (lbl, lbl_flip) in enumerate(zip(labels, labels_flip)):
                lbl_flip.flip_lr_()  # 翻转bbox坐标
                labels[i] = lbl + lbl_flip
            new_data[k] = labels
        
        data['is_hflip'] = np.array([False] * B + [True] * B)
        data = new_data
    
    # Padding到模型输入大小
    ev_repr = self.input_padder.pad_tensor_ev_repr(ev_repr)
    data[DataType.EV_REPR] = [ev for ev in ev_repr]
    
    return data
```

#### 3.3 `predict_step` - 生成伪标签

```python
def predict_step(self, batch: Any, batch_idx: int):
    """
    对单个batch生成伪标签
    
    流程:
        1. 获取数据 (带TTA)
        2. 模型推理 (逐帧)
        3. 后处理 (NMS, 阈值过滤)
        4. 转换为Prophesee格式
        5. 累积到EventSeqData
        6. 如果是序列末尾，保存伪标签
    """
    
    # 步骤1: 准备数据
    data = self.get_data_from_batch(batch)
    worker_id = self.get_worker_id_from_batch(batch)
    
    # 步骤2: 模型推理
    ev_tensor_sequence = data[DataType.EV_REPR]  # [L, B, C, H, W]
    sparse_obj_labels = data[DataType.OBJLABELS_SEQ]
    
    # 重置RNN状态
    is_first_sample = data[DataType.IS_FIRST_SAMPLE]
    self.mode_2_rnn_states[mode].reset(worker_id, is_first_sample)
    
    prev_states = self.mode_2_rnn_states[mode].get_states(worker_id)
    backbone_feature_selector = BackboneFeatureSelector()
    obj_labels = list()
    
    # 逐帧处理
    for tidx in range(L):
        ev_tensors = ev_tensor_sequence[tidx]  # [B, C, H, W]
        
        # Recurrent backbone
        backbone_features, states = self.mdl.forward_backbone(
            x=ev_tensors,
            previous_states=prev_states
        )
        prev_states = states
        
        # 收集有标签的帧
        current_labels, valid_batch_indices = \
            sparse_obj_labels[tidx].get_valid_labels_and_batch_indices()
        
        if len(current_labels) > 0:
            backbone_feature_selector.add_backbone_features(
                backbone_features=backbone_features,
                selected_indices=valid_batch_indices
            )
            obj_labels.extend(current_labels)
    
    # 更新状态
    self.mode_2_rnn_states[mode].save_states_and_detach(worker_id, prev_states)
    
    # 步骤3: 检测头预测
    selected_backbone_features = \
        backbone_feature_selector.get_batched_backbone_features()
    predictions, _ = self.mdl.forward_detect(
        backbone_features=selected_backbone_features
    )
    
    # 步骤4: 后处理
    pred_processed = postprocess(
        prediction=predictions,
        num_classes=self.num_classes,
        conf_thre=self.mdl_config.postprocess.confidence_threshold,
        nms_thre=self.mdl_config.postprocess.nms_threshold
    )
    
    # 步骤5: 转换为Prophesee格式
    loaded_labels_proph, yolox_preds_proph = \
        to_prophesee(obj_labels, pred_processed)
    
    # 步骤6: 过滤预测框
    filtered_preds = []
    for pred, label in zip(yolox_preds_proph, loaded_labels_proph):
        if label is not None and label.is_gt_label().any():
            # 如果有GT标签且use_gt=True，使用GT
            if self.use_gt:
                filtered_preds.append(label)
            else:
                filtered_preds.append(pred)
        else:
            # 使用模型预测
            pred = self.filter_bbox_fn(pred)  # 数据集特定过滤
            pred = self.score_filter(pred)     # 置信度过滤
            filtered_preds.append(pred)
    
    # 步骤7: 累积到EventSeqData
    self.collect_data_post_forward(
        data=data,
        preds=filtered_preds
    )
    
    # 步骤8: 如果序列结束，保存伪标签
    ev_paths = data[DataType.PATH]
    is_last_sample = data[DataType.IS_LAST_SAMPLE]
    
    for i, (path, is_last) in enumerate(zip(ev_paths, is_last_sample)):
        if is_last:
            ev_seq_data = self.ev_path_2_ev_data[path]
            ev_seq_data.save(self.save_dir, self.dst_name)
            del self.ev_path_2_ev_data[path]
```

---

## 使用示例

### 基础用法

```bash
python predict.py \
    model=pseudo_labeler \
    dataset=gen1x0.01_ss \
    dataset.path=./datasets/gen1/ \
    checkpoint="path/to/model.ckpt" \
    hardware.gpus=0 \
    +experiment/gen1="small.yaml" \
    save_dir=./datasets/pseudo_gen1/gen1x0.01_ss-1round/train
```

### 启用TTA

```bash
python predict.py \
    ... \
    tta.enable=True \
    tta.hflip=True \
    tta.tflip=False  # 可选，时间翻转（2x时间）
```

### 调整过滤阈值

```bash
python predict.py \
    ... \
    model.postprocess.confidence_threshold=0.01 \  # NMS前的阈值
    model.pseudo_label.obj_thresh=0.01 \           # objectness阈值
    model.pseudo_label.cls_thresh=0.01 \           # class conf阈值
    model.pseudo_label.min_track_len=6 \           # 最小轨迹长度
    model.pseudo_label.inpaint=True                # 启用填充
```

### 验证伪标签质量

```bash
python val_dst.py \
    model=pseudo_labeler \
    dataset=gen1x0.01_ss \
    dataset.path=./datasets/pseudo_gen1/gen1x0.01_ss-1round \
    checkpoint=1 \
    +experiment/gen1="small.yaml"
```

---

## 关键参数调优建议

### 1. 置信度阈值

| 阈值 | 精度 | 召回率 | 适用场景 |
|-----|------|--------|---------|
| 0.01 | 中 | 高 | 平衡（推荐） |
| 0.03 | 高 | 中 | 追求高质量 |
| 0.005 | 低 | 很高 | 追求覆盖度 |

### 2. 跟踪长度

| min_track_len | 过滤强度 | 适用场景 |
|---------------|---------|---------|
| 4 | 弱 | 快速移动物体 |
| 6 | 中 (推荐) | 平衡 |
| 8 | 强 | 静止或慢速物体 |

### 3. TTA策略

| TTA | 时间成本 | 质量提升 | 推荐 |
|-----|---------|---------|------|
| 无 | 1x | 基线 | 仅测试 |
| hflip | 2x | +2-3% | ✓ 推荐 |
| hflip+tflip | 4x | +3-5% | 追求极致 |

---

## 常见问题

### Q1: 伪标签生成太慢怎么办？

A: 
1. 关闭tflip (只用hflip)
2. 增加batch size
3. 使用更快的GPU
4. 减少confidence_threshold (更早过滤)

### Q2: 伪标签质量不高怎么办？

A:
1. 检查预训练模型的性能（至少25% mAP）
2. 提高obj_thresh和cls_thresh
3. 增加min_track_len
4. 启用双向跟踪

### Q3: 如何平衡精度和召回率？

A:
- 高精度: obj_thresh=0.03, min_track_len=8
- 高召回: obj_thresh=0.01, min_track_len=4
- 平衡: obj_thresh=0.01, min_track_len=6 (推荐)

---

## 总结

`PseudoLabeler`是LEOD的核心创新，通过：
1. **TTA增强**: 提高预测鲁棒性
2. **跟踪过滤**: 利用时间一致性
3. **轨迹填充**: 增加标注密度

生成高质量的伪标签，显著提升弱监督学习性能。

---

*本文档帮助理解LEOD伪标签生成的实现细节。*
